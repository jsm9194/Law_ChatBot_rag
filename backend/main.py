from fastapi import FastAPI, Depends
from pydantic import BaseModel
from openai import OpenAI
import os
import json
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse # ìŠ¤íŠ¸ë¦¬ë°ì‹ ë‹µë³€ì¶œë ¥

# âœ… DB ê´€ë ¨ import
from sqlalchemy.orm import Session
from DB.database import SessionLocal
from DB.models import ChatLog

# ë¼ìš°í„°
from routers import conversations, messages


# íˆ´ ëª¨ë“ˆ
from query_qdrant import ask as ask_law
from case_api import search_case_list, get_case_detail
from search_goolge import google_search

# íˆ´ ì •ì˜ ë¶ˆëŸ¬ì˜¤ê¸°
from tools_config import tools

app = FastAPI()
app.include_router(conversations.router)
app.include_router(messages.router)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===============================
# CORS
# ===============================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # React dev ì„œë²„ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===============================
# DB ì„¸ì…˜ ì˜ì¡´ì„±
# ===============================
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ===============================
# ìš”ì²­ Body
# ===============================
class Query(BaseModel):
    conversation_id: str
    question: str

# ===============================
# ì‹¤ì œ íˆ´ í•¨ìˆ˜ ë§¤í•‘
# ===============================
def call_tool(name: str, arguments: dict):
    print("âš¡ [TOOL CALL]")
    print(f"  ğŸ“Œ ì‹¤í–‰ëœ íˆ´: {name}")
    print(f"  ğŸ“ ì „ë‹¬ ì¸ì: {json.dumps(arguments, ensure_ascii=False)}")

    if name == "law":
        result = ask_law(arguments["query"])

    elif name == "search_cases":
        # ìƒì„¸ì¡°íšŒ ìš”ì²­ì¸ë° search_casesë¡œ ì˜ëª» ì˜¨ ê²½ìš° ë³´ì •
        if "case_id" in arguments:
            # case_id ê¸°ë°˜ ìƒì„¸ì¡°íšŒ
            result = get_case_detail(arguments["case_id"])
        elif "nb" in arguments and not arguments.get("query"):
            # ì‚¬ê±´ë²ˆí˜¸(nb)ë§Œ ë“¤ì–´ì˜¨ ê²½ìš° â†’ ìƒì„¸ì¡°íšŒë¡œ ë³´ì •
            result = get_case_detail(arguments["nb"])
        else:
            # ì •ìƒì ì¸ ê²€ìƒ‰ ìš”ì²­
            result = {"cases": search_case_list(**arguments)}

    elif name == "case_detail":
        result = get_case_detail(arguments["case_id"])

    elif name == "web_search":
        result = google_search(
            arguments["query"],
            arguments.get("count", 5),
            arguments.get("time_range", "any")
        )

    else:
        result = {"error": f"Unknown tool: {name}"}

    # âœ… íˆ´ ê²°ê³¼ë„ ë¡œê¹…
    preview = str(result)
    if len(preview) > 500:  # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
        preview = preview[:500] + " ... (ìƒëµ)"
    print(f"  âœ… íˆ´ ê²°ê³¼: {preview}\n")

    return result

    
# ===============================
# /ask ì—”ë“œí¬ì¸íŠ¸ (DB ê¸°ë°˜ history ì¶”ê°€)
# ===============================
@app.post("/ask")
def ask_api(query: Query, db: Session = Depends(get_db)):
    print("\nğŸš€ [ASK í˜¸ì¶œë¨]")
    print(f"  ëŒ€í™” ID: {query.conversation_id}")
    print(f"  ì§ˆë¬¸: {query.question}\n")

    # âœ… DBì—ì„œ ìµœê·¼ 10ê°œ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°
    logs = (
        db.query(ChatLog)
        .filter(ChatLog.conversation_id == query.conversation_id)
        .order_by(ChatLog.created_at.desc())
        .limit(10)
        .all()
    )
    history_text = "\n".join([f"{log.role}: {log.content}" for log in reversed(logs)])
    print(f"  íˆìŠ¤í† ë¦¬: \n{history_text}")

    # ===============================
    # 1ì°¨ ìš”ì²­: íˆ´ì½œ ì—¬ë¶€ íŒë‹¨
    # ===============================
    first_response = client.chat.completions.create(
        model="gpt-4o-mini",  # íˆ´ì½œ í—ˆìš© ëª¨ë¸
        messages=[
            {
                "role": "system",
                "content": (
                    "ë„ˆì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ íˆ´ í˜¸ì¶œì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ëŠ” ê²ƒì´ë‹¤.\n\n"
                    "íˆ´ ì„ íƒ ê·œì¹™:\n"
                    "- ë²•ë ¹/ì¡°ë¬¸ ì§ˆë¬¸ â†’ ë°˜ë“œì‹œ law íˆ´ í˜¸ì¶œ\n"
                    "- íŒë¡€ ì§ˆë¬¸ â†’ search_cases ë˜ëŠ” case_detail í˜¸ì¶œ\n"
                    "- ìµœì‹  ë‰´ìŠ¤/ì›¹ìë£Œ ì§ˆë¬¸ â†’ web_search í˜¸ì¶œ\n"
                    "- ê·¸ ì™¸ íˆ´ì´ í•„ìš” ì—†ëŠ” ì§ˆë¬¸ â†’ ì§ì ‘ ë‹µë³€\n\n"
                    "íˆ´ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°ì—ëŠ” ë°˜ë“œì‹œ tool_callsë¡œ ë°˜í™˜í•˜ê³ , "
                    "íˆ´ì´ í•„ìš” ì—†ìœ¼ë©´ ì§ì ‘ ë‹µë³€ì„ ì œê³µí•œë‹¤.\n"
                ),
            },
            {"role": "user", "content": history_text},
            {"role": "user", "content": query.question},
        ],
        tools=tools,
        tool_choice="auto",
    )

    message = first_response.choices[0].message

    # ===============================
    # íˆ´ì½œë§ ì—¬ë¶€ í™•ì¸
    # ===============================
    if message.tool_calls:
        prep_message = message.content or "ê²€ìƒ‰í•´ ì •ë³´ë¥¼ ì°¾ì•„ì˜¤ê² ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."

        tool_results_texts = []
        all_sources = []

        for tool_call in message.tool_calls:
            name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)
            tool_result = call_tool(name, arguments)

            # íˆ´ ê²°ê³¼ ë¬¸ìì—´í™”
            tool_results_texts.append(json.dumps(tool_result, ensure_ascii=False))

            if "sources" in tool_result:
                all_sources.extend(tool_result["sources"])

        # system í”„ë¡¬í”„íŠ¸ìš© ì¶œì²˜ í…ìŠ¤íŠ¸
        sources_text = "\n".join([
            f"- {s.get('law','')} {s.get('article','')} â†’ {s.get('url','')}"
            for s in all_sources
        ])

        # ===============================
        # 2ì°¨ ìš”ì²­: íˆ´ ê²°ê³¼ ê¸°ë°˜ ìµœì¢… ë‹µë³€
        # ===============================
        followup = client.chat.completions.create(
            model="gpt-4o-mini",  # followupì€ íˆ´ì½œ ê¸ˆì§€
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë„ˆëŠ” í•œêµ­ ì‹œì„¤ê´€ë¦¬ ë²•ë ¹Â·íŒë¡€Â·ë‰´ìŠ¤ ìƒë‹´ ì±—ë´‡ì´ë‹¤.\n\n"
                        "âš ï¸ ì£¼ì–´ì§„ íˆ´ ê²°ê³¼ë§Œ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ë¼. "
                        "ìƒˆë¡œìš´ íˆ´ í˜¸ì¶œì€ ì ˆëŒ€ í•˜ì§€ ë§ˆë¼.\n\n"
                        "ë‹µë³€ ì‘ì„± ê·œì¹™:\n"
                        "- ë‰´ìŠ¤: ê¸°ì‚¬ë§ˆë‹¤ 3ë¬¸ì¥ ì´ë‚´ í•µì‹¬ ìš”ì•½ + `[ê¸°ì‚¬ ì œëª©](URL)` í˜•ì‹ ë§í¬\n"
                        "- ë²•ë ¹: `[ë²•ë ¹ëª… ì œooì¡°](URL)` í˜•ì‹ìœ¼ë¡œ ë§í¬\n"
                        "- íŒë¡€: ì‚¬ê±´ ë°°ê²½ â†’ íŒê²° ì´ìœ  â†’ ê²°ë¡  ìˆœ ìš”ì•½\n"
                        "- ê²°ê³¼ ì—†ìœ¼ë©´ 'ê´€ë ¨ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ê¸°\n"
                        "- ë¬¸ë‹¨ì€ ë‘ ì¤„ ê°„ê²©ìœ¼ë¡œ êµ¬ë¶„, ë¶ˆë¦¿/ë²ˆí˜¸ëª©ë¡ ì ê·¹ í™œìš©\n"
                        "- ì¤‘ìš”í•œ í‚¤ì›Œë“œëŠ” **êµµê²Œ** í‘œì‹œ, ğŸ™‚ âš¡ ğŸ“Œ ê°™ì€ ì´ëª¨ì§€ í¬ì¸íŠ¸ë¡œ í™œìš©\n\n"
                        f"Sources:\n{sources_text}"
                    ),
                },
                {"role": "user", "content": query.question},
                {"role": "assistant", "content": prep_message},
                {
                    "role": "system",
                    "content": "ì•„ë˜ëŠ” íˆ´ ì‹¤í–‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n" + "\n\n".join(tool_results_texts),
                },
            ],
        )

        return {
            "prep": prep_message,
            "answer": followup.choices[0].message.content,
            "sources": all_sources,
        }

    # ===============================
    # íˆ´ì½œë§ ë¶ˆí•„ìš” â†’ ë°”ë¡œ ë‹µë³€
    # ===============================
    return {"answer": message.content}


