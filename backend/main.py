from fastapi import FastAPI, Depends, Request
from pydantic import BaseModel
from openai import OpenAI
import os
import json
import traceback
from typing import Iterator, List, Dict, Any, Optional
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse

# âœ… DB ê´€ë ¨ import
from sqlalchemy.orm import Session
from DB.database import SessionLocal
from DB.models import ChatLog

# ë¼ìš°í„°
from routers import conversations, messages

# íˆ´ ëª¨ë“ˆ
from query_qdrant import ask as ask_law
from case_api import search_case_list, get_case_detail
from search_goolge import google_search

# íˆ´ ì •ì˜ ë¶ˆëŸ¬ì˜¤ê¸° (Chat Completionsìš© function-calling ìŠ¤í‚¤ë§ˆ)
from tools_config import tools

# ì¿¼ë¦¬ì— ë‚ ì§œ
from datetime import datetime

# ===============================
# ì•± & í´ë¼ì´ì–¸íŠ¸
# ===============================
app = FastAPI()
app.include_router(conversations.router)
app.include_router(messages.router)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

VALID_MESSAGE_ROLES = {"system", "assistant", "user", "tool", "function", "developer"}

# ===============================
# CORS
# ===============================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # React dev ì„œë²„ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===============================
# DB ì„¸ì…˜ ì˜ì¡´ì„±
# ===============================
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ===============================
# ìš”ì²­ Body
# ===============================
class Query(BaseModel):
    conversation_id: str
    question: str


# ë‚ ì§œ ë¶ˆëŸ¬ì˜¤ê¸°
def get_current_datetime() -> str:
    """í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ YYYY-MM-DD HH:MM í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    return datetime.now().strftime("%Y-%m-%d %H:%M")



# ===============================
# ì¿¼ë¦¬ ìµœì í™” í”„ë¡¬í”„íŠ¸
# ===============================
QUERY_OPTIMIZATION_SYSTEM = """
ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë°›ì•„, êµ¬ê¸€ ê²€ìƒ‰ì—ì„œ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ì„¸íŠ¸ë¥¼ í•œêµ­ì–´ì™€ ì˜ì–´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.  
í˜„ì¬ 2025ë…„ 10ì›” ì…ë‹ˆë‹¤.

ê·œì¹™:  
1. í•œêµ­ì–´ ì¿¼ë¦¬ì™€ ì˜ì–´ ì¿¼ë¦¬ë¥¼ ëª¨ë‘ ìƒì„±í•˜ì„¸ìš”.  
2. ê° ì–¸ì–´ë³„ë¡œ ìµœì†Œ 5ê°œ ì´ìƒì˜ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.  
   - ë‰´ìŠ¤/ì‹œì‚¬ ê´€ë ¨ ì¿¼ë¦¬  
   - ìœ„í‚¤/ë°±ê³¼ì‚¬ì „ìš© ì¿¼ë¦¬  
   - í•´ì™¸ ì–¸ë¡ (Reuters, NYT, TIME ë“±)ìš© ì¿¼ë¦¬  
   - ê¸°ìˆ /ì „ë¬¸ ìë£Œìš© ì¿¼ë¦¬  
   - ìµœì‹  ì •ë³´(ìµœê·¼/ì˜¬í•´ ë“± í¬í•¨)  
3. ì¿¼ë¦¬ëŠ” ì§§ê³  ëª…í™•í•˜ê²Œ (2~6 ë‹¨ì–´) ì‘ì„±í•˜ì„¸ìš”.  
4. ë¶ˆí•„ìš”í•œ ì¡°ì‚¬/ì ‘ì†ì‚¬ëŠ” ì œê±°í•˜ì„¸ìš”.  
5. ê²°ê³¼ëŠ” JSONìœ¼ë¡œ ì¶œë ¥í•˜ë˜ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”.  

ì¶œë ¥ í˜•ì‹ (ì˜ˆì‹œ):
{
  "ko": ["ì¹´ì¹´ì˜¤í†¡ ë¡¤ë°±", "ì¹´ì¹´ì˜¤í†¡ ì—…ë°ì´íŠ¸ ë…¼ë€", "ì¹´ì¹´ì˜¤í†¡ í”¼ë“œë°±", "ì¹´ì¹´ì˜¤í†¡ ìµœê·¼ ë‰´ìŠ¤", "ì¹´ì¹´ì˜¤í†¡ ì‚¬ìš©ì ë°˜ë°œ"],
  "en": ["KakaoTalk rollback", "KakaoTalk update controversy", "KakaoTalk user backlash", "KakaoTalk latest news", "KakaoTalk criticism Reuters"]
}
"""

def optimize_search_query(question: str) -> List[str]:
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",  # ë˜ëŠ” ë‹¹ì‹ ì´ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸
            messages=[
                {"role": "system", "content": QUERY_OPTIMIZATION_SYSTEM},
                {"role": "user", "content": question}
            ],
            temperature=0.3,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ temperature
        )
        
        result = response.choices[0].message.content
        # JSON íŒŒì‹± ì‹œë„
        try:
            queries = json.loads(result)
            if isinstance(queries, dict) and "ko" in queries and "en" in queries:
                return queries
            
            if isinstance(queries, list) and len(queries) > 0:
                return {"ko": queries, "en": []}
        except:
            print(f"ì¿¼ë¦¬ ìµœì í™” ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {result}")
            
    except Exception as e:
        print(f"ì¿¼ë¦¬ ìµœì í™” ì˜¤ë¥˜: {str(e)}")
    
    # ì‹¤íŒ¨ ì‹œ ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë¦¬í„´
    return {"ko": [question], "en": []}

# ===============================
# ê²€ìƒ‰ ê²°ê³¼ ë¦¬ë­í‚¹ í”„ë¡¬í”„íŠ¸
# ===============================
SEARCH_RERANKING_SYSTEM = """
ë‹¹ì‹ ì€ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
ì‚¬ìš©ìì˜ ì§ˆë¬¸(í•œêµ­ì–´ì¼ ìˆ˜ë„ ìˆê³  ì˜ì–´ì¼ ìˆ˜ë„ ìˆìŒ)ê³¼ ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡(í•œêµ­ì–´ì™€ ì˜ì–´ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆìŒ)ì„ ë°›ì•„, ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë“¤ì„ ì„ ë³„í•˜ì„¸ìš”.  

ê·œì¹™:  
1. ì§ˆë¬¸ì´ í•œêµ­ì–´ë¼ë„ ì˜ì–´ ê²°ê³¼ë¥¼ ë¬´ì‹œí•˜ì§€ ë§ˆì„¸ìš”. ì œëª©/ìŠ¤ë‹ˆí«ì´ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ ìˆë‹¤ë©´ ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ì„¸ìš”.  
2. ê° ê²€ìƒ‰ ê²°ê³¼ì˜ ì œëª©ê³¼ ìŠ¤ë‹ˆí«ì„ ë¶„ì„í•´, ì§ˆë¬¸ ì˜ë„ì™€ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”.  
3. í•œêµ­ì–´/ì˜ì–´ ê²°ê³¼ ì¤‘ë³µì€ ì œê±°í•˜ì„¸ìš”. (ê°™ì€ ë‚´ìš©ì„ ë‹¤ë£¬ë‹¤ë©´ í•˜ë‚˜ë§Œ ì„ íƒ)  
4. ìµœì‹  ì •ë³´ë¥¼ ìš°ì„ ì‹œí•˜ì„¸ìš”. (ì¶œíŒì¼ì´ ì–¸ê¸‰ëœ ê²½ìš° ìµœê·¼ ê²ƒì„ ìš°ì„ )  
5. í•„ìš”í•˜ë©´ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ ì˜ë¯¸ë¥¼ ì´í•´í•œ ë’¤ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì„¸ìš”.  

ì¶œë ¥ í˜•ì‹ì€ ê´€ë ¨ì„±ì´ ë†’ì€ ê²°ê³¼ë“¤ì˜ ì¸ë±ìŠ¤ë§Œ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
[0, 2, 5]

ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì •ë³´ ì—†ì´ ì˜¤ì§ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

def rerank_search_results(question: str, search_results: List[Dict]) -> List[Dict]:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§ˆë¬¸ ê´€ë ¨ì„±ì— ë”°ë¼ ë¦¬ë­í‚¹"""
    try:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if len(search_results) <= 5:
            return search_results
            
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        results_text = []
        for i, result in enumerate(search_results):
            title = result.get("title", "ì œëª© ì—†ìŒ")
            snippet = result.get("snippet", "ë‚´ìš© ì—†ìŒ")
            results_text.append(f"[{i}] ì œëª©: {title}\në‚´ìš©: {snippet}")
        
        all_results = "\n\n".join(results_text)
        
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": SEARCH_RERANKING_SYSTEM},
                {"role": "user", "content": f"ì§ˆë¬¸: {question}\n\nê²€ìƒ‰ ê²°ê³¼:\n{all_results}"}
            ],
            temperature=0.2,
        )
        
        result = response.choices[0].message.content
        # JSON íŒŒì‹± ì‹œë„
        try:
            indices = json.loads(result)
            if isinstance(indices, list) and len(indices) > 0:
                # ì¸ë±ìŠ¤ë¡œ ê²°ê³¼ í•„í„°ë§
                return [search_results[i] for i in indices if i < len(search_results)]
        except:
            print(f"ë¦¬ë­í‚¹ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {result}")
            pass
            
    except Exception as e:
        print(f"ë¦¬ë­í‚¹ ì˜¤ë¥˜: {str(e)}")
    
    # ì‹¤íŒ¨ ì‹œ ì›ë˜ ê²°ê³¼ ê·¸ëŒ€ë¡œ ë¦¬í„´ (ìµœëŒ€ 5ê°œ)
    return search_results[:min(5, len(search_results))]

# ===============================
# í–¥ìƒëœ ì›¹ ê²€ìƒ‰ í•¨ìˆ˜
# ===============================
def enhanced_web_search(query: str, count: int = 8, time_range: str = "any"):
    """ì¿¼ë¦¬ ìµœì í™” ë° ê²°ê³¼ ë¦¬ë­í‚¹ì„ ì ìš©í•œ í–¥ìƒëœ ì›¹ ê²€ìƒ‰"""
    # 1. ì¿¼ë¦¬ ìµœì í™”
    optimized_queries = optimize_search_query(query)
    print(f"  ğŸ” ìµœì í™”ëœ ì¿¼ë¦¬: {optimized_queries}")
    
    all_results = []

    merged_queries = optimized_queries.get("ko", []) + optimized_queries.get("en", [])

    # 2. ê° ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ì‹¤í–‰
    for opt_query in merged_queries:  # âœ… ì´ì œ ì—¬ê¸°ì„œ ìŠ¬ë¼ì´ì‹± ì—ëŸ¬ ì•ˆ ë‚¨
        results = google_search(opt_query, count, time_range)
        if isinstance(results, list):
            all_results.extend(results)
        elif isinstance(results, dict) and "results" in results:
            all_results.extend(results["results"])
    
    # 3. ê²°ê³¼ ë¦¬ë­í‚¹
    if all_results:
        reranked_results = rerank_search_results(query, all_results)
        print(f"  ğŸ“Š ë¦¬ë­í‚¹ í›„ ê²°ê³¼ ìˆ˜: {len(reranked_results)}")
        return {"results": reranked_results}
    
    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë˜ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
    return google_search(query, count, time_range)

# ===============================
# ì‹¤ì œ íˆ´ í•¨ìˆ˜ ë§¤í•‘
# ===============================
def call_tool(name: str, arguments: dict):
    print("âš¡ [TOOL CALL]")
    print(f"  ğŸ“Œ ì‹¤í–‰ëœ íˆ´: {name}")
    print(f"  ğŸ“ ì „ë‹¬ ì¸ì: {json.dumps(arguments, ensure_ascii=False)}")

    if name == "law":
        result = ask_law(arguments["query"])

    elif name == "search_cases":
        if "case_id" in arguments:
            result = get_case_detail(arguments["case_id"])
        elif "nb" in arguments and not arguments.get("query"):
            result = get_case_detail(arguments["nb"])
        else:
            result = {"cases": search_case_list(**arguments)}

    elif name == "case_detail":
        result = get_case_detail(arguments["case_id"])

    elif name == "web_search":
        # â­â­â­ ê¸°ì¡´ google_search ëŒ€ì‹  enhanced_web_search ì‚¬ìš© â­â­â­
        result = enhanced_web_search(
            arguments["query"],
            arguments.get("count", 8), # enhanced_web_search ë‚´ë¶€ì—ì„œ ê²€ìƒ‰ ì¿¼ë¦¬ë³„ë¡œ ë” ë§ì€ ê²°ê³¼ íƒìƒ‰
            arguments.get("time_range", "any")
        )

    else:
        result = {"error": f"Unknown tool: {name}"}

    # âœ… íˆ´ ê²°ê³¼ë„ ë¡œê¹…(ë¯¸ë¦¬ë³´ê¸°)
    preview = str(result)
    if len(preview) > 500:
        preview = preview[:500] + " ... (ìƒëµ)"
    print(f"  âœ… íˆ´ ê²°ê³¼: {preview}\n")
    return result

# ===============================
# ìœ í‹¸: SSE í¬ë§·
# ===============================
def _sse(event: str, data: Any) -> str:
    if not isinstance(data, str):
        data = json.dumps(data, ensure_ascii=False)
    lines = data.splitlines()
    if not lines:
        lines = [""]
    formatted_data = "\n".join(f"data: {line}" for line in lines)
    return f"event: {event}\n{formatted_data}\n\n"

# ===============================
# ìœ í‹¸: íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
# ===============================
FOLLOWUP_SYSTEM = """
ë‹¹ì‹ ì€ ì „ë¬¸ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.  
ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¼ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.

âš¡ ì¶œë ¥ ê·œì¹™ (ì—„ê²©íˆ ì§€ì¼œì•¼ í•¨)
1. ë°˜ë“œì‹œ **Markdown í˜•ì‹**ë§Œ ì‚¬ìš© (HTML, ë²„íŠ¼, ì´ëª¨ì§€, 'ì¶œì²˜', 'ë°”ë¡œê°€ê¸°' ê°™ì€ í‘œí˜„ ê¸ˆì§€).
2. ë‹µë³€ì€ í•­ìƒ ë‘ ì„¹ì…˜ìœ¼ë¡œ ì‘ì„±:
   ## ê´€ë ¨ ë²•ë¥  ìš”ì•½
   - **ë²•ë ¹ëª… (ì œXXì¡°)**  
     ì„¤ëª… í•œ ì¤„  
     [ì¶œì²˜](URL)

   - ë™ì¼ ë²•ë ¹ì˜ ì—¬ëŸ¬ ì¡°ë¬¸ë„ ìœ„ì™€ ê°™ì´ ê°ê° ë¶ˆë¦¿Â·ì¤„ë°”ê¿ˆ
3. ## ì‚¬ì—…ì¥ ì•ˆì „ê´€ë¦¬ í•µì‹¬ ì¡°ì¹˜  
   1. ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±  
   2. ê° í•­ëª©ì€ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ê¸°ìˆ   
   3. í•­ëª© ì‚¬ì´ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ ìœ ì§€
4. ë§í¬ëŠ” ë°˜ë“œì‹œ `[ì¶œì²˜](URL)` í˜•ì‹ìœ¼ë¡œë§Œ í‘œì‹œ.  
   ë‹¤ë¥¸ í‘œí˜„(ì˜ˆ: 'ì¶œì²˜:', 'ë°”ë¡œê°€ê¸°', URL ë‹¨ë…)ì€ ì ˆëŒ€ ê¸ˆì§€.
5. ë¬¸ë‹¨Â·ë¶ˆë¦¿Â·ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„ í•œ ì¤„ ë°˜ë“œì‹œ ë„£ì„ ê²ƒ.
"""

def build_followup_messages(
    question: str,
    prep_message: str,
    tool_results_texts: Optional[List[str]] = None
) -> List[Dict[str, Any]]:
    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": FOLLOWUP_SYSTEM},
        {"role": "user", "content": question},
    ]
    # ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì•ˆì •í™”í•˜ê¸° ìœ„í•´ 'assistant preface' ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë„£ì–´ì¤€ë‹¤.
    if prep_message:
        messages.append({"role": "assistant", "content": prep_message})

    if tool_results_texts:
        joined = "ì•„ë˜ëŠ” íˆ´ ì‹¤í–‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n" + "\n\n".join(tool_results_texts)
        messages.append({"role": "system", "content": joined})
    return messages

# ===============================
# í•µì‹¬: /ask ì—”ë“œí¬ì¸íŠ¸
#  - Accept í—¤ë”ê°€ text/event-streamì´ë©´ SSE ìŠ¤íŠ¸ë¦¬ë°
#  - ì•„ë‹ˆë©´ JSON ì‘ë‹µ(ê¸°ì¡´ í˜¸í™˜)
# ===============================
@app.post("/ask")
def ask_api(query: Query, request: Request, db: Session = Depends(get_db)):
    print("\nğŸš€ [ASK í˜¸ì¶œë¨]")
    print(f"  ëŒ€í™” ID: {query.conversation_id}")
    print(f"  ì§ˆë¬¸: {query.question}\n")

    # âœ… DBì—ì„œ ìµœê·¼ 10ê°œ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì‹  10ê°œ)
    logs = (
        db.query(ChatLog)
        .filter(ChatLog.conversation_id == query.conversation_id)
        .order_by(ChatLog.created_at.desc())
        .limit(10)
        .all()
    )
    # ë¡œê·¸ë¥¼ ë’¤ì§‘ì–´ì„œ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    history_messages: List[Dict[str, str]] = []
    for log in reversed(logs):
        normalized_role = (log.role or "").strip().lower()
        if normalized_role not in VALID_MESSAGE_ROLES:
            print(
                "  âš ï¸ ëŒ€í™” ë¡œê·¸ ë¬´ì‹œ (ìœ íš¨í•˜ì§€ ì•Šì€ role)",
                {"id": getattr(log, "id", None), "role": log.role},
            )
            continue

        content = log.content or ""
        if not content.strip():
            print(
                "  âš ï¸ ëŒ€í™” ë¡œê·¸ ë¬´ì‹œ (ë¹ˆ content)",
                {"id": getattr(log, "id", None)},
            )
            continue

        history_messages.append({"role": normalized_role, "content": content})
    
    # íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    print("  === ê³¼ê±° ëŒ€í™” ë¡œê·¸ ===")
    for msg in history_messages:
        print(f"  {msg['role']}: {msg['content']}")
    print("  ====================")


    # ===============================
    # 1ì°¨: íˆ´ì½œ ì—¬ë¶€ íŒë‹¨ (Chat Completions)
    #  - ìŠ¤íŠ¸ë¦¬ë° ë¶ˆí•„ìš”, ë¹ ë¥´ê²Œ ì˜ì‚¬ê²°ì •
    # ===============================
    # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë¥¼ íˆ´ í˜¸ì¶œ íŒë‹¨ì—ë„ í™œìš©
    messages_for_tool_call = history_messages + [
        {
            "role": "system",
            "content": 
            """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
í•„ìš”í•˜ë‹¤ë©´ ì—¬ëŸ¬ ê°œì˜ ë„êµ¬ë¥¼ ë™ì‹œì— í˜¸ì¶œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  
ë¶ˆí•„ìš”í•œ ë„êµ¬ëŠ” í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.""",
        },
        {"role": "user", "content": query.question},
    ]

    first = client.chat.completions.create(
        model="gpt-4.1-mini",  # íˆ´ ì½œ ì •í™•ë„ë¥¼ ìœ„í•´ gpt-4o ì‚¬ìš© ì¶”ì²œ
        messages=messages_for_tool_call,
        tools=tools,
        tool_choice="auto", # autoëŠ” ëª¨ë¸ì´ íŒë‹¨í•˜ë„ë¡ í•¨
    )

    # íˆ´ í˜¸ì¶œì´ í•„ìš”í•œì§€ íŒë‹¨
    tool_calls = first.choices[0].message.tool_calls
    # ì²« ì‘ë‹µ ë©”ì‹œì§€ê°€ íˆ´ í˜¸ì¶œ ì—†ì´ ë°”ë¡œ ì»¨í…ì¸ ë¥¼ í¬í•¨í•  ìˆ˜ë„ ìˆìŒ
    prep_message = first.choices[0].message.content or "" 

    # ===============================
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¤€ë¹„ (Accept í—¤ë”ì— ë”°ë¼)
    # ===============================
    is_streaming = "text/event-stream" in request.headers.get("accept", "")

    # ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹ˆë©´ ê¸°ì¡´ JSON ì‘ë‹µ ë°©ì‹
    if not is_streaming:
        # ===============================
        # ë¹„ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë¡œì§ (ê¸°ì¡´ í˜¸í™˜)
        # ===============================
        tool_results = []
        tool_results_texts = []

        if tool_calls:
            print("  [ë¹„ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì‹¤í–‰ ì¤‘...")
            for tc in tool_calls:
                try:
                    tool_name = tc.function.name
                    args = json.loads(tc.function.arguments)
                    tool_result = call_tool(tool_name, args)
                    tool_results.append(tool_result)
                    tool_results_texts.append(f"[{tool_name}] ê²°ê³¼:\n{json.dumps(tool_result, ensure_ascii=False)}")
                except Exception as e:
                    print(f"  [ë¹„ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
                    traceback.print_exc()

        # íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
        # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
        final_messages = history_messages + build_followup_messages(
            query.question, prep_message, tool_results_texts
        )

        # ìµœì¢… ë‹µë³€ ìƒì„±
        completion = client.chat.completions.create(
            model="gpt-4.1-mini", # ìµœì¢… ë‹µë³€ë„ gpt-4o ì‚¬ìš© ì¶”ì²œ
            messages=final_messages,
        )
        answer = completion.choices[0].message.content

        # DBì— ì €ì¥
        db.add(
            ChatLog(
                conversation_id=query.conversation_id,
                user_id="assistant",  # AIì˜ ì‘ë‹µì´ë¯€ë¡œ roleì€ assistant
                content=answer,
            )
        )
        db.commit()

        return {
            "answer": answer,
            "sources": tool_results,
        }

    # ===============================
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë¡œì§ (SSE)
    # ===============================
    from typing import AsyncIterator

    async def _stream_response_generator() -> AsyncIterator[str]:
        # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì „ì— ë¨¼ì € ì €ì¥
        db_session = SessionLocal() # ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° ë‚´ì—ì„œ DB ì„¸ì…˜ ìƒˆë¡œ ìƒì„±
        try:
            db_session.add(
                ChatLog(
                    conversation_id=query.conversation_id,
                    user_id="user",
                    content=query.question,
                )
            )
            db_session.commit()
            
            # ì´ˆê¸° í”„ë¦¬í˜ì´ìŠ¤ ë©”ì‹œì§€ ì „ì†¡
            if prep_message:
                yield _sse("prep", prep_message)

            tool_results = []
            tool_results_texts = []

            # íˆ´ í˜¸ì¶œì´ ìˆìœ¼ë©´ ì‹¤í–‰
            if tool_calls:
                print("  [ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì‹¤í–‰ ì¤‘...")
                for tc in tool_calls:
                    try:
                        tool_name = tc.function.name
                        args = json.loads(tc.function.arguments)
                        
                        # íˆ´ í˜¸ì¶œ
                        tool_result = call_tool(tool_name, args)
                        tool_results.append(tool_result)
                        
                        result_text = f"[{tool_name}] ê²°ê³¼:\n{json.dumps(tool_result, ensure_ascii=False)}"
                        tool_results_texts.append(result_text)
                        
                        # ì†ŒìŠ¤ ì •ë³´ ì „ì†¡
                        # í´ë¼ì´ì–¸íŠ¸ì—ì„œ sourceë¥¼ ë°›ì•„ì„œ ë³„ë„ UIë¡œ í‘œì‹œ ê°€ëŠ¥
                        if tool_result:
                            yield _sse("sources", tool_result)
                            
                    except Exception as e:
                        error_msg = f"íˆ´ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"
                        print(error_msg)
                        traceback.print_exc()
                        yield _sse("error", error_msg)

            try:
                # íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
                # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
                final_messages = history_messages + build_followup_messages(
                    query.question, prep_message, tool_results_texts
                )

                # ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
                stream = client.chat.completions.create(
                    model="gpt-4.1-mini", # ìµœì¢… ë‹µë³€ë„ gpt-4o ì‚¬ìš© ì¶”ì²œ
                    messages=final_messages,
                    stream=True,
                )

                collected_chunks = []
                for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        collected_chunks.append(content)
                        yield _sse("chunk", content)

                # ì „ì²´ ë‹µë³€ ì €ì¥
                full_answer = "".join(collected_chunks)
                
                # DBì— ì €ì¥ (assistant ë©”ì‹œì§€)
                db_session.add(
                    ChatLog(
                        conversation_id=query.conversation_id,
                        user_id="assistant",
                        content=full_answer,
                    )
                )
                db_session.commit()
                
                # ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
                yield _sse("done", {"status": "complete"})
                
            except Exception as e:
                error_msg = f"ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                print(error_msg)
                traceback.print_exc()
                yield _sse("error", error_msg)
        finally:
            db_session.close() # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚˜ë©´ DB ì„¸ì…˜ ë‹«ê¸°


    return StreamingResponse(_stream_response_generator(), media_type="text/event-stream")