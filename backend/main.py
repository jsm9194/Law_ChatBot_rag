from fastapi import FastAPI, Depends, Request
from pydantic import BaseModel
from openai import OpenAI
import os
import json
import traceback
from typing import Iterator, List, Dict, Any, Optional
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse

# âœ… DB ê´€ë ¨ import
from sqlalchemy.orm import Session
from DB.database import SessionLocal
from DB.models import ChatLog

# ë¼ìš°í„°
from routers import conversations, messages

# íˆ´ ëª¨ë“ˆ
from query_qdrant import ask as ask_law
from case_api import search_case_list, get_case_detail
from search_goolge import google_search

# íˆ´ ì •ì˜ ë¶ˆëŸ¬ì˜¤ê¸° (Chat Completionsìš© function-calling ìŠ¤í‚¤ë§ˆ)
from tools_config import tools

# ===============================
# ì•± & í´ë¼ì´ì–¸íŠ¸
# ===============================
app = FastAPI()
app.include_router(conversations.router)
app.include_router(messages.router)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===============================
# CORS
# ===============================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # React dev ì„œë²„ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===============================
# DB ì„¸ì…˜ ì˜ì¡´ì„±
# ===============================
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ===============================
# ìš”ì²­ Body
# ===============================
class Query(BaseModel):
    conversation_id: str
    question: str

# ===============================
# ì¿¼ë¦¬ ìµœì í™” í”„ë¡¬í”„íŠ¸
# ===============================
QUERY_OPTIMIZATION_SYSTEM = """ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë°›ì•„, êµ¬ê¸€ ê²€ìƒ‰ì—ì„œ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. ì›ë˜ ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œì™€ ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
2. ê²€ìƒ‰ì—”ì§„ì— ìµœì í™”ëœ 3ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
3. ê° ì¿¼ë¦¬ëŠ” ì§§ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš” (ë³´í†µ 2-5ê°œ ë‹¨ì–´).
4. ì‹œê°„ì— ë¯¼ê°í•œ ì§ˆë¬¸ì´ë¼ë©´ ì—°ë„ë‚˜ 'ìµœì‹ ', 'ìµœê·¼' ê°™ì€ ì‹œê°„ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì„¸ìš”.
5. ì „ë¬¸ ìš©ì–´ê°€ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.
6. ë¶ˆí•„ìš”í•œ ì¡°ì‚¬, ì ‘ì†ì‚¬ëŠ” ì œì™¸í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ì€ JSON ë°°ì—´ë¡œ ì •í™•íˆ ë‹¤ìŒê³¼ ê°™ì´ í•´ì£¼ì„¸ìš”:
["ì¿¼ë¦¬1", "ì¿¼ë¦¬2", "ì¿¼ë¦¬3"]

ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì •ë³´ ì—†ì´ ì˜¤ì§ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

def optimize_search_query(question: str) -> List[str]:
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # ë˜ëŠ” ë‹¹ì‹ ì´ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸
            messages=[
                {"role": "system", "content": QUERY_OPTIMIZATION_SYSTEM},
                {"role": "user", "content": question}
            ],
            temperature=0.3,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ temperature
        )
        
        result = response.choices[0].message.content
        # JSON íŒŒì‹± ì‹œë„
        try:
            queries = json.loads(result)
            if isinstance(queries, list) and len(queries) > 0:
                return queries
        except:
            print(f"ì¿¼ë¦¬ ìµœì í™” ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {result}")
            pass
            
    except Exception as e:
        print(f"ì¿¼ë¦¬ ìµœì í™” ì˜¤ë¥˜: {str(e)}")
    
    # ì‹¤íŒ¨ ì‹œ ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë¦¬í„´
    return [question]

# ===============================
# ê²€ìƒ‰ ê²°ê³¼ ë¦¬ë­í‚¹ í”„ë¡¬í”„íŠ¸
# ===============================
SEARCH_RERANKING_SYSTEM = """ë‹¹ì‹ ì€ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì›ë˜ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡ì„ ë°›ì•„, ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë“¤ì„ ì„ ë³„í•˜ì„¸ìš”.

ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. ê° ê²€ìƒ‰ ê²°ê³¼ì˜ ì œëª©ê³¼ ìŠ¤ë‹ˆí«ì„ ë¶„ì„í•˜ì„¸ìš”.
2. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì„¸ìš”.
3. ê´€ë ¨ì„±ì´ ë†’ì€ ìƒìœ„ 3-5ê°œ ê²°ê³¼ë§Œ ì„ íƒí•˜ì„¸ìš”.
4. ì¤‘ë³µëœ ì •ë³´ëŠ” ì œê±°í•˜ì„¸ìš”.
5. ìµœì‹  ì •ë³´ë¥¼ ìš°ì„ ì‹œí•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ì€ ê´€ë ¨ì„±ì´ ë†’ì€ ê²°ê³¼ë“¤ì˜ ì¸ë±ìŠ¤ë§Œ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
[0, 2, 5]  # ì´ëŠ” 0ë²ˆ, 2ë²ˆ, 5ë²ˆ ê²°ê³¼ê°€ ê°€ì¥ ê´€ë ¨ì„± ë†’ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.

ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì •ë³´ ì—†ì´ ì˜¤ì§ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

def rerank_search_results(question: str, search_results: List[Dict]) -> List[Dict]:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§ˆë¬¸ ê´€ë ¨ì„±ì— ë”°ë¼ ë¦¬ë­í‚¹"""
    try:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if len(search_results) <= 5:
            return search_results
            
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        results_text = []
        for i, result in enumerate(search_results):
            title = result.get("title", "ì œëª© ì—†ìŒ")
            snippet = result.get("snippet", "ë‚´ìš© ì—†ìŒ")
            results_text.append(f"[{i}] ì œëª©: {title}\në‚´ìš©: {snippet}")
        
        all_results = "\n\n".join(results_text)
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": SEARCH_RERANKING_SYSTEM},
                {"role": "user", "content": f"ì§ˆë¬¸: {question}\n\nê²€ìƒ‰ ê²°ê³¼:\n{all_results}"}
            ],
            temperature=0.2,
        )
        
        result = response.choices[0].message.content
        # JSON íŒŒì‹± ì‹œë„
        try:
            indices = json.loads(result)
            if isinstance(indices, list) and len(indices) > 0:
                # ì¸ë±ìŠ¤ë¡œ ê²°ê³¼ í•„í„°ë§
                return [search_results[i] for i in indices if i < len(search_results)]
        except:
            print(f"ë¦¬ë­í‚¹ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {result}")
            pass
            
    except Exception as e:
        print(f"ë¦¬ë­í‚¹ ì˜¤ë¥˜: {str(e)}")
    
    # ì‹¤íŒ¨ ì‹œ ì›ë˜ ê²°ê³¼ ê·¸ëŒ€ë¡œ ë¦¬í„´ (ìµœëŒ€ 5ê°œ)
    return search_results[:min(5, len(search_results))]

# ===============================
# í–¥ìƒëœ ì›¹ ê²€ìƒ‰ í•¨ìˆ˜
# ===============================
def enhanced_web_search(query: str, count: int = 8, time_range: str = "any"):
    """ì¿¼ë¦¬ ìµœì í™” ë° ê²°ê³¼ ë¦¬ë­í‚¹ì„ ì ìš©í•œ í–¥ìƒëœ ì›¹ ê²€ìƒ‰"""
    # 1. ì¿¼ë¦¬ ìµœì í™”
    optimized_queries = optimize_search_query(query)
    print(f"  ğŸ” ìµœì í™”ëœ ì¿¼ë¦¬: {optimized_queries}")
    
    all_results = []
    # 2. ê° ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ì‹¤í–‰
    for opt_query in optimized_queries[:2]:  # ìƒìœ„ 2ê°œ ì¿¼ë¦¬ë§Œ ì‚¬ìš©
        results = google_search(opt_query, count, time_range)
        if isinstance(results, list):
            all_results.extend(results)
        elif isinstance(results, dict) and "results" in results:
            all_results.extend(results["results"])
    
    # 3. ê²°ê³¼ ë¦¬ë­í‚¹
    if all_results:
        reranked_results = rerank_search_results(query, all_results)
        print(f"  ğŸ“Š ë¦¬ë­í‚¹ í›„ ê²°ê³¼ ìˆ˜: {len(reranked_results)}")
        return {"results": reranked_results}
    
    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë˜ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
    return google_search(query, count, time_range)

# ===============================
# ì‹¤ì œ íˆ´ í•¨ìˆ˜ ë§¤í•‘
# ===============================
def call_tool(name: str, arguments: dict):
    print("âš¡ [TOOL CALL]")
    print(f"  ğŸ“Œ ì‹¤í–‰ëœ íˆ´: {name}")
    print(f"  ğŸ“ ì „ë‹¬ ì¸ì: {json.dumps(arguments, ensure_ascii=False)}")

    if name == "law":
        result = ask_law(arguments["query"])

    elif name == "search_cases":
        if "case_id" in arguments:
            result = get_case_detail(arguments["case_id"])
        elif "nb" in arguments and not arguments.get("query"):
            result = get_case_detail(arguments["nb"])
        else:
            result = {"cases": search_case_list(**arguments)}

    elif name == "case_detail":
        result = get_case_detail(arguments["case_id"])

    elif name == "web_search":
        # â­â­â­ ê¸°ì¡´ google_search ëŒ€ì‹  enhanced_web_search ì‚¬ìš© â­â­â­
        result = enhanced_web_search(
            arguments["query"],
            arguments.get("count", 8), # enhanced_web_search ë‚´ë¶€ì—ì„œ ê²€ìƒ‰ ì¿¼ë¦¬ë³„ë¡œ ë” ë§ì€ ê²°ê³¼ íƒìƒ‰
            arguments.get("time_range", "any")
        )

    else:
        result = {"error": f"Unknown tool: {name}"}

    # âœ… íˆ´ ê²°ê³¼ë„ ë¡œê¹…(ë¯¸ë¦¬ë³´ê¸°)
    preview = str(result)
    if len(preview) > 500:
        preview = preview[:500] + " ... (ìƒëµ)"
    print(f"  âœ… íˆ´ ê²°ê³¼: {preview}\n")
    return result

# ===============================
# ìœ í‹¸: SSE í¬ë§·
# ===============================
def _sse(event: str, data: Any) -> str:
    if not isinstance(data, str):
        data = json.dumps(data, ensure_ascii=False)
    return f"event: {event}\ndata: {data}\n\n"

# ===============================
# ìœ í‹¸: íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
# ===============================
FOLLOWUP_SYSTEM = """ë‹¹ì‹ ì€ ì „ë¬¸ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” (ìˆë‹¤ë©´) íˆ´(web_search, ë²•ë ¹ê²€ìƒ‰, íŒë¡€ê²€ìƒ‰ ë“±)ì—ì„œ ì „ë‹¬ëœ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

âš¡ï¸ ì¶œë ¥ ê·œì¹™ (ì—„ê²©íˆ ì§€ì¼œì•¼ í•¨)
1. **ë§ˆí¬ë‹¤ìš´ í˜•ì‹**ë§Œ ì‚¬ìš© (HTML íƒœê·¸ ê¸ˆì§€)
2. ë¬¸ë‹¨ ê°„ ë‘ ì¤„ ê°„ê²© ìœ ì§€
3. ì œëª©/ì†Œì œëª©ì€ `#`, `##`, `###`ë¥¼ ìƒí™©ì— ë§ê²Œ ì‚¬ìš©
4. í•µì‹¬ì€ ë¶ˆë¦¿í¬ì¸íŠ¸(`-`), ë‹¨ê³„/íƒ€ì„ë¼ì¸ì€ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸(`1.`)
5. ê¸°ì‚¬Â·ë¬¸ì„œÂ·ì¶œì²˜ëŠ” ìš”ì•½ ì˜†ì— `[ì¶œì²˜ëª…](URL)`ë¡œ ë°”ë¡œ ë§í¬
6. ì¶œì²˜ê°€ ì—¬ëŸ¬ ê°œë©´ ë™ì¼ ì£¼ì œ ì•„ë˜ì— ë‚˜ë€íˆ ì—°ê²° (ì˜ˆ: `ğŸ‘‰ [ì—°í•©ë‰´ìŠ¤](url) | [í•œê²¨ë ˆ](url)`)
7. ë¶ˆí•„ìš”í•œ ì‚¬ì¡± ê¸ˆì§€. ë°ì´í„° ì—†ìœ¼ë©´ `ê´€ë ¨ ìë£Œ ì—†ìŒ` í•œ ì¤„ë¡œ.
"""

def build_followup_messages(
    question: str,
    prep_message: str,
    tool_results_texts: Optional[List[str]] = None
) -> List[Dict[str, Any]]:
    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": FOLLOWUP_SYSTEM},
        {"role": "user", "content": question},
    ]
    # ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì•ˆì •í™”í•˜ê¸° ìœ„í•´ 'assistant preface' ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë„£ì–´ì¤€ë‹¤.
    if prep_message:
        messages.append({"role": "assistant", "content": prep_message})

    if tool_results_texts:
        joined = "ì•„ë˜ëŠ” íˆ´ ì‹¤í–‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n" + "\n\n".join(tool_results_texts)
        messages.append({"role": "system", "content": joined})
    return messages

# ===============================
# í•µì‹¬: /ask ì—”ë“œí¬ì¸íŠ¸
#  - Accept í—¤ë”ê°€ text/event-streamì´ë©´ SSE ìŠ¤íŠ¸ë¦¬ë°
#  - ì•„ë‹ˆë©´ JSON ì‘ë‹µ(ê¸°ì¡´ í˜¸í™˜)
# ===============================
@app.post("/ask")
def ask_api(query: Query, request: Request, db: Session = Depends(get_db)):
    print("\nğŸš€ [ASK í˜¸ì¶œë¨]")
    print(f"  ëŒ€í™” ID: {query.conversation_id}")
    print(f"  ì§ˆë¬¸: {query.question}\n")

    # âœ… DBì—ì„œ ìµœê·¼ 10ê°œ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì‹  10ê°œ)
    logs = (
        db.query(ChatLog)
        .filter(ChatLog.conversation_id == query.conversation_id)
        .order_by(ChatLog.created_at.desc())
        .limit(10)
        .all()
    )
    # ë¡œê·¸ë¥¼ ë’¤ì§‘ì–´ì„œ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    history_messages = [
        {"role": log.role, "content": log.content} for log in reversed(logs)
    ]
    
    # íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    print("  === ê³¼ê±° ëŒ€í™” ë¡œê·¸ ===")
    for msg in history_messages:
        print(f"  {msg['role']}: {msg['content']}")
    print("  ====================")


    # ===============================
    # 1ì°¨: íˆ´ì½œ ì—¬ë¶€ íŒë‹¨ (Chat Completions)
    #  - ìŠ¤íŠ¸ë¦¬ë° ë¶ˆí•„ìš”, ë¹ ë¥´ê²Œ ì˜ì‚¬ê²°ì •
    # ===============================
    # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë¥¼ íˆ´ í˜¸ì¶œ íŒë‹¨ì—ë„ í™œìš©
    messages_for_tool_call = history_messages + [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë„êµ¬ë“¤ ì¤‘ì—ì„œ ì ì ˆí•œ ê²ƒì„ ì„ íƒí•˜ì„¸ìš”. ê³¼ê±° ëŒ€í™” ë§¥ë½ì„ ì´í•´í•˜ê³  ë„êµ¬ ì‚¬ìš©ì„ ê²°ì •í•˜ì„¸ìš”.",
        },
        {"role": "user", "content": query.question},
    ]

    first = client.chat.completions.create(
        model="gpt-4.1-mini",  # íˆ´ ì½œ ì •í™•ë„ë¥¼ ìœ„í•´ gpt-4o ì‚¬ìš© ì¶”ì²œ
        messages=messages_for_tool_call,
        tools=tools,
        tool_choice="auto", # autoëŠ” ëª¨ë¸ì´ íŒë‹¨í•˜ë„ë¡ í•¨
    )

    # íˆ´ í˜¸ì¶œì´ í•„ìš”í•œì§€ íŒë‹¨
    tool_calls = first.choices[0].message.tool_calls
    # ì²« ì‘ë‹µ ë©”ì‹œì§€ê°€ íˆ´ í˜¸ì¶œ ì—†ì´ ë°”ë¡œ ì»¨í…ì¸ ë¥¼ í¬í•¨í•  ìˆ˜ë„ ìˆìŒ
    prep_message = first.choices[0].message.content or "" 

    # ===============================
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¤€ë¹„ (Accept í—¤ë”ì— ë”°ë¼)
    # ===============================
    is_streaming = "text/event-stream" in request.headers.get("accept", "")

    # ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹ˆë©´ ê¸°ì¡´ JSON ì‘ë‹µ ë°©ì‹
    if not is_streaming:
        # ===============================
        # ë¹„ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë¡œì§ (ê¸°ì¡´ í˜¸í™˜)
        # ===============================
        tool_results = []
        tool_results_texts = []

        if tool_calls:
            print("  [ë¹„ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì‹¤í–‰ ì¤‘...")
            for tc in tool_calls:
                try:
                    tool_name = tc.function.name
                    args = json.loads(tc.function.arguments)
                    tool_result = call_tool(tool_name, args)
                    tool_results.append(tool_result)
                    tool_results_texts.append(f"[{tool_name}] ê²°ê³¼:\n{json.dumps(tool_result, ensure_ascii=False)}")
                except Exception as e:
                    print(f"  [ë¹„ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
                    traceback.print_exc()

        # íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
        # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
        final_messages = history_messages + build_followup_messages(
            query.question, prep_message, tool_results_texts
        )

        # ìµœì¢… ë‹µë³€ ìƒì„±
        completion = client.chat.completions.create(
            model="gpt-4o", # ìµœì¢… ë‹µë³€ë„ gpt-4o ì‚¬ìš© ì¶”ì²œ
            messages=final_messages,
        )
        answer = completion.choices[0].message.content

        # DBì— ì €ì¥
        db.add(
            ChatLog(
                conversation_id=query.conversation_id,
                user_id="assistant",  # AIì˜ ì‘ë‹µì´ë¯€ë¡œ roleì€ assistant
                content=answer,
            )
        )
        db.commit()

        return {
            "answer": answer,
            "sources": tool_results,
        }

    # ===============================
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë¡œì§ (SSE)
    # ===============================
    from typing import AsyncIterator

    async def _stream_response_generator() -> AsyncIterator[str]:
        # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì „ì— ë¨¼ì € ì €ì¥
        db_session = SessionLocal() # ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° ë‚´ì—ì„œ DB ì„¸ì…˜ ìƒˆë¡œ ìƒì„±
        try:
            db_session.add(
                ChatLog(
                    conversation_id=query.conversation_id,
                    user_id="user",
                    content=query.question,
                )
            )
            db_session.commit()
            
            # ì´ˆê¸° í”„ë¦¬í˜ì´ìŠ¤ ë©”ì‹œì§€ ì „ì†¡
            if prep_message:
                yield _sse("prep", prep_message)

            tool_results = []
            tool_results_texts = []

            # íˆ´ í˜¸ì¶œì´ ìˆìœ¼ë©´ ì‹¤í–‰
            if tool_calls:
                print("  [ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì‹¤í–‰ ì¤‘...")
                for tc in tool_calls:
                    try:
                        tool_name = tc.function.name
                        args = json.loads(tc.function.arguments)
                        
                        # íˆ´ í˜¸ì¶œ
                        tool_result = call_tool(tool_name, args)
                        tool_results.append(tool_result)
                        
                        result_text = f"[{tool_name}] ê²°ê³¼:\n{json.dumps(tool_result, ensure_ascii=False)}"
                        tool_results_texts.append(result_text)
                        
                        # ì†ŒìŠ¤ ì •ë³´ ì „ì†¡
                        # í´ë¼ì´ì–¸íŠ¸ì—ì„œ sourceë¥¼ ë°›ì•„ì„œ ë³„ë„ UIë¡œ í‘œì‹œ ê°€ëŠ¥
                        if tool_result:
                            yield _sse("sources", tool_result)
                            
                    except Exception as e:
                        error_msg = f"íˆ´ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"
                        print(error_msg)
                        traceback.print_exc()
                        yield _sse("error", error_msg)

            try:
                # íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
                # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
                final_messages = history_messages + build_followup_messages(
                    query.question, prep_message, tool_results_texts
                )

                # ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
                stream = client.chat.completions.create(
                    model="gpt-4o", # ìµœì¢… ë‹µë³€ë„ gpt-4o ì‚¬ìš© ì¶”ì²œ
                    messages=final_messages,
                    stream=True,
                )

                collected_chunks = []
                for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        collected_chunks.append(content)
                        yield _sse("chunk", content)

                # ì „ì²´ ë‹µë³€ ì €ì¥
                full_answer = "".join(collected_chunks)
                
                # DBì— ì €ì¥ (assistant ë©”ì‹œì§€)
                db_session.add(
                    ChatLog(
                        conversation_id=query.conversation_id,
                        user_id="assistant",
                        content=full_answer,
                    )
                )
                db_session.commit()
                
                # ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
                yield _sse("done", {"status": "complete"})
                
            except Exception as e:
                error_msg = f"ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                print(error_msg)
                traceback.print_exc()
                yield _sse("error", error_msg)
        finally:
            db_session.close() # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚˜ë©´ DB ì„¸ì…˜ ë‹«ê¸°


    return StreamingResponse(_stream_response_generator(), media_type="text/event-stream")