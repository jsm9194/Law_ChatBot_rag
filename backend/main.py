from fastapi import FastAPI, Depends, Request
from pydantic import BaseModel
from openai import OpenAI
import os
import json
import traceback
from typing import Iterator, List, Dict, Any, Optional
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse

# âœ… DB ê´€ë ¨ import
from sqlalchemy.orm import Session
from DB.database import SessionLocal
from DB.models import ChatLog

# ë¼ìš°í„°
from routers import conversations, messages

# íˆ´ ëª¨ë“ˆ
from query_qdrant import ask as ask_law
from case_api import search_case_list, get_case_detail
from search_goolge import google_search

# íˆ´ ì •ì˜ ë¶ˆëŸ¬ì˜¤ê¸° (Chat Completionsìš© function-calling ìŠ¤í‚¤ë§ˆ)
from tools_config import tools
from prompts import load_prompt_text, select_followup_prompt

# ì¿¼ë¦¬ì— ë‚ ì§œ
from datetime import datetime

# ===============================
# ì•± & í´ë¼ì´ì–¸íŠ¸
# ===============================
app = FastAPI()
app.include_router(conversations.router)
app.include_router(messages.router)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

VALID_MESSAGE_ROLES = {"system", "assistant", "user", "tool", "function", "developer"}

# ===============================
# CORS
# ===============================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # React dev ì„œë²„ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===============================
# DB ì„¸ì…˜ ì˜ì¡´ì„±
# ===============================
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ===============================
# ìš”ì²­ Body
# ===============================
class Query(BaseModel):
    conversation_id: str
    question: str


# ë‚ ì§œ ë¶ˆëŸ¬ì˜¤ê¸°
def get_current_datetime() -> str:
    """í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ YYYY-MM-DD HH:MM í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    return datetime.now().strftime("%Y-%m-%d %H:%M")



# ===============================
# ì¿¼ë¦¬ ìµœì í™” í”„ë¡¬í”„íŠ¸
# ===============================
QUERY_OPTIMIZATION_SYSTEM = load_prompt_text("query_optimization.md")

def optimize_search_query(question: str) -> List[str]:
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",  # ë˜ëŠ” ë‹¹ì‹ ì´ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸
            messages=[
                {"role": "system", "content": QUERY_OPTIMIZATION_SYSTEM},
                {"role": "user", "content": question}
            ],
            temperature=0.3,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ temperature
        )
        
        result = response.choices[0].message.content
        # JSON íŒŒì‹± ì‹œë„
        try:
            queries = json.loads(result)
            if isinstance(queries, dict) and "ko" in queries and "en" in queries:
                return queries
            
            if isinstance(queries, list) and len(queries) > 0:
                return {"ko": queries, "en": []}
        except:
            print(f"ì¿¼ë¦¬ ìµœì í™” ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {result}")
            
    except Exception as e:
        print(f"ì¿¼ë¦¬ ìµœì í™” ì˜¤ë¥˜: {str(e)}")
    
    # ì‹¤íŒ¨ ì‹œ ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë¦¬í„´
    return {"ko": [question], "en": []}

# ===============================
# ê²€ìƒ‰ ê²°ê³¼ ë¦¬ë­í‚¹ í”„ë¡¬í”„íŠ¸
# ===============================
SEARCH_RERANKING_SYSTEM = load_prompt_text("search_reranking.md")
TOOL_SELECTION_SYSTEM = load_prompt_text("tool_selection.md")

def rerank_search_results(question: str, search_results: List[Dict]) -> List[Dict]:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§ˆë¬¸ ê´€ë ¨ì„±ì— ë”°ë¼ ë¦¬ë­í‚¹"""
    try:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if len(search_results) <= 5:
            return search_results
            
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        results_text = []
        for i, result in enumerate(search_results):
            title = result.get("title", "ì œëª© ì—†ìŒ")
            snippet = result.get("snippet", "ë‚´ìš© ì—†ìŒ")
            results_text.append(f"[{i}] ì œëª©: {title}\në‚´ìš©: {snippet}")
        
        all_results = "\n\n".join(results_text)
        
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": SEARCH_RERANKING_SYSTEM},
                {"role": "user", "content": f"ì§ˆë¬¸: {question}\n\nê²€ìƒ‰ ê²°ê³¼:\n{all_results}"}
            ],
            temperature=0.2,
        )
        
        result = response.choices[0].message.content
        # JSON íŒŒì‹± ì‹œë„
        try:
            indices = json.loads(result)
            if isinstance(indices, list) and len(indices) > 0:
                # ì¸ë±ìŠ¤ë¡œ ê²°ê³¼ í•„í„°ë§
                return [search_results[i] for i in indices if i < len(search_results)]
        except:
            print(f"ë¦¬ë­í‚¹ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {result}")
            pass
            
    except Exception as e:
        print(f"ë¦¬ë­í‚¹ ì˜¤ë¥˜: {str(e)}")
    
    # ì‹¤íŒ¨ ì‹œ ì›ë˜ ê²°ê³¼ ê·¸ëŒ€ë¡œ ë¦¬í„´ (ìµœëŒ€ 5ê°œ)
    return search_results[:min(5, len(search_results))]

# ===============================
# í–¥ìƒëœ ì›¹ ê²€ìƒ‰ í•¨ìˆ˜
# ===============================
def enhanced_web_search(query: str, count: int = 8, time_range: str = "any"):
    """ì¿¼ë¦¬ ìµœì í™” ë° ê²°ê³¼ ë¦¬ë­í‚¹ì„ ì ìš©í•œ í–¥ìƒëœ ì›¹ ê²€ìƒ‰"""
    # 1. ì¿¼ë¦¬ ìµœì í™”
    optimized_queries = optimize_search_query(query)
    print(f"  ğŸ” ìµœì í™”ëœ ì¿¼ë¦¬: {optimized_queries}")
    
    all_results = []

    merged_queries = optimized_queries.get("ko", []) + optimized_queries.get("en", [])

    # 2. ê° ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ì‹¤í–‰
    for opt_query in merged_queries:  # âœ… ì´ì œ ì—¬ê¸°ì„œ ìŠ¬ë¼ì´ì‹± ì—ëŸ¬ ì•ˆ ë‚¨
        results = google_search(opt_query, count, time_range)
        if isinstance(results, list):
            all_results.extend(results)
        elif isinstance(results, dict) and "results" in results:
            all_results.extend(results["results"])
    
    # 3. ê²°ê³¼ ë¦¬ë­í‚¹
    if all_results:
        reranked_results = rerank_search_results(query, all_results)
        print(f"  ğŸ“Š ë¦¬ë­í‚¹ í›„ ê²°ê³¼ ìˆ˜: {len(reranked_results)}")
        return {"results": reranked_results}
    
    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë˜ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
    return google_search(query, count, time_range)

# ===============================
# ì‹¤ì œ íˆ´ í•¨ìˆ˜ ë§¤í•‘
# ===============================
def call_tool(name: str, arguments: dict):
    print("âš¡ [TOOL CALL]")
    print(f"  ğŸ“Œ ì‹¤í–‰ëœ íˆ´: {name}")
    print(f"  ğŸ“ ì „ë‹¬ ì¸ì: {json.dumps(arguments, ensure_ascii=False)}")

    if name == "law":
        result = ask_law(arguments["query"])

    elif name == "search_cases":
        if "case_id" in arguments:
            result = get_case_detail(arguments["case_id"])
        elif "nb" in arguments and not arguments.get("query"):
            result = get_case_detail(arguments["nb"])
        else:
            result = {"cases": search_case_list(**arguments)}

    elif name == "case_detail":
        result = get_case_detail(arguments["case_id"])

    elif name == "web_search":
        # â­â­â­ ê¸°ì¡´ google_search ëŒ€ì‹  enhanced_web_search ì‚¬ìš© â­â­â­
        result = enhanced_web_search(
            arguments["query"],
            arguments.get("count", 8), # enhanced_web_search ë‚´ë¶€ì—ì„œ ê²€ìƒ‰ ì¿¼ë¦¬ë³„ë¡œ ë” ë§ì€ ê²°ê³¼ íƒìƒ‰
            arguments.get("time_range", "any")
        )

    else:
        result = {"error": f"Unknown tool: {name}"}

    # âœ… íˆ´ ê²°ê³¼ë„ ë¡œê¹…(ë¯¸ë¦¬ë³´ê¸°)
    preview = str(result)
    if len(preview) > 500:
        preview = preview[:500] + " ... (ìƒëµ)"
    print(f"  âœ… íˆ´ ê²°ê³¼: {preview}\n")
    return result

# ===============================
# ìœ í‹¸: SSE í¬ë§·
# ===============================
def _sse(event: str, data: Any) -> str:
    if not isinstance(data, str):
        data = json.dumps(data, ensure_ascii=False)
    lines = data.splitlines()
    if not lines:
        lines = [""]
    formatted_data = "\n".join(f"data: {line}" for line in lines)
    return f"event: {event}\n{formatted_data}\n\n"

# ===============================
# ìœ í‹¸: íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
# ===============================
def build_followup_messages(
    question: str,
    prep_message: str,
    tool_results_texts: Optional[List[str]] = None,
    tool_names: Optional[List[str]] = None,
) -> List[Dict[str, Any]]:
    selection = select_followup_prompt(question, tool_names, tool_results_texts)
    tags_text = ", ".join(sorted(selection.tags))
    print(f"  [PROMPT] ì‚¬ìš©ëœ ì‘ë‹µ í”„ë¡¬í”„íŠ¸: {selection.name} (tags={tags_text})")

    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": selection.content},
        {"role": "user", "content": question},
    ]
    if prep_message:
        messages.append({"role": "assistant", "content": prep_message})

    if tool_results_texts:
        joined_header = "ì•„ë˜ëŠ” ì´ë²ˆì— ìˆ˜í–‰í•œ ë„êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n"
        joined = joined_header + "\n\n".join(tool_results_texts)
        messages.append({"role": "system", "content": joined})
        messages.append({"role": "system", "content": joined})

    return messages

# ===============================
# í•µì‹¬: /ask ì—”ë“œí¬ì¸íŠ¸
#  - Accept í—¤ë”ê°€ text/event-streamì´ë©´ SSE ìŠ¤íŠ¸ë¦¬ë°
#  - ì•„ë‹ˆë©´ JSON ì‘ë‹µ(ê¸°ì¡´ í˜¸í™˜)
# ===============================
@app.post("/ask")
def ask_api(query: Query, request: Request, db: Session = Depends(get_db)):
    print("\nğŸš€ [ASK í˜¸ì¶œë¨]")
    print(f"  ëŒ€í™” ID: {query.conversation_id}")
    print(f"  ì§ˆë¬¸: {query.question}\n")

    # âœ… DBì—ì„œ ìµœê·¼ 10ê°œ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì‹  10ê°œ)
    logs = (
        db.query(ChatLog)
        .filter(ChatLog.conversation_id == query.conversation_id)
        .order_by(ChatLog.created_at.desc())
        .limit(10)
        .all()
    )
    # ë¡œê·¸ë¥¼ ë’¤ì§‘ì–´ì„œ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    history_messages: List[Dict[str, str]] = []
    for log in reversed(logs):
        normalized_role = (log.role or "").strip().lower()
        if normalized_role not in VALID_MESSAGE_ROLES:
            print(
                "  âš ï¸ ëŒ€í™” ë¡œê·¸ ë¬´ì‹œ (ìœ íš¨í•˜ì§€ ì•Šì€ role)",
                {"id": getattr(log, "id", None), "role": log.role},
            )
            continue

        content = log.content or ""
        if not content.strip():
            print(
                "  âš ï¸ ëŒ€í™” ë¡œê·¸ ë¬´ì‹œ (ë¹ˆ content)",
                {"id": getattr(log, "id", None)},
            )
            continue

        history_messages.append({"role": normalized_role, "content": content})
    
    # íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    print("  === ê³¼ê±° ëŒ€í™” ë¡œê·¸ ===")
    for msg in history_messages:
        print(f"  {msg['role']}: {msg['content']}")
    print("  ====================")


    # ===============================
    # 1ì°¨: íˆ´ì½œ ì—¬ë¶€ íŒë‹¨ (Chat Completions)
    #  - ìŠ¤íŠ¸ë¦¬ë° ë¶ˆí•„ìš”, ë¹ ë¥´ê²Œ ì˜ì‚¬ê²°ì •
    # ===============================
    # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë¥¼ íˆ´ í˜¸ì¶œ íŒë‹¨ì—ë„ í™œìš©
    messages_for_tool_call = history_messages + [
{"role": "system", "content": TOOL_SELECTION_SYSTEM},
        {"role": "user", "content": query.question},
    ]

    first = client.chat.completions.create(
        model="gpt-4.1-mini",  # íˆ´ ì½œ ì •í™•ë„ë¥¼ ìœ„í•´ gpt-4o ì‚¬ìš© ì¶”ì²œ
        messages=messages_for_tool_call,
        tools=tools,
        tool_choice="auto", # autoëŠ” ëª¨ë¸ì´ íŒë‹¨í•˜ë„ë¡ í•¨
    )

    # íˆ´ í˜¸ì¶œì´ í•„ìš”í•œì§€ íŒë‹¨
    tool_calls = first.choices[0].message.tool_calls
    planned_tool_names = [tc.function.name for tc in tool_calls] if tool_calls else []
    # ì²« ì‘ë‹µ ë©”ì‹œì§€ê°€ íˆ´ í˜¸ì¶œ ì—†ì´ ë°”ë¡œ ì»¨í…ì¸ ë¥¼ í¬í•¨í•  ìˆ˜ë„ ìˆìŒ
    prep_message = first.choices[0].message.content or "" 

    # ===============================
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¤€ë¹„ (Accept í—¤ë”ì— ë”°ë¼)
    # ===============================
    is_streaming = "text/event-stream" in request.headers.get("accept", "")

    # ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹ˆë©´ ê¸°ì¡´ JSON ì‘ë‹µ ë°©ì‹
    if not is_streaming:
        # ===============================
        # ë¹„ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë¡œì§ (ê¸°ì¡´ í˜¸í™˜)
        # ===============================
        tool_results = []
        tool_results_texts = []
        executed_tool_names: List[str] = []

        if tool_calls:
            print("  [ë¹„ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì‹¤í–‰ ì¤‘...")
            for tc in tool_calls:
                try:
                    tool_name = tc.function.name
                    args = json.loads(tc.function.arguments)
                    tool_result = call_tool(tool_name, args)
                    tool_results.append(tool_result)
                    executed_tool_names.append(tool_name)
                    tool_results_texts.append(f"[{tool_name}] ê²°ê³¼:\n{json.dumps(tool_result, ensure_ascii=False)}")
                except Exception as e:
                    print(f"  [ë¹„ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
                    traceback.print_exc()

        # íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
        # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
        final_messages = history_messages + build_followup_messages(
            query.question, prep_message, tool_results_texts, executed_tool_names or planned_tool_names
        )

        # ìµœì¢… ë‹µë³€ ìƒì„±
        completion = client.chat.completions.create(
            model="gpt-4.1-mini", # ìµœì¢… ë‹µë³€ë„ gpt-4o ì‚¬ìš© ì¶”ì²œ
            messages=final_messages,
        )
        answer = completion.choices[0].message.content

        # DBì— ì €ì¥
        db.add(
            ChatLog(
                conversation_id=query.conversation_id,
                user_id="assistant",  # AIì˜ ì‘ë‹µì´ë¯€ë¡œ roleì€ assistant
                content=answer,
            )
        )
        db.commit()

        return {
            "answer": answer,
            "sources": tool_results,
        }

    # ===============================
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë¡œì§ (SSE)
    # ===============================
    from typing import AsyncIterator

    async def _stream_response_generator() -> AsyncIterator[str]:
        # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì „ì— ë¨¼ì € ì €ì¥
        db_session = SessionLocal() # ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° ë‚´ì—ì„œ DB ì„¸ì…˜ ìƒˆë¡œ ìƒì„±
        try:
            db_session.add(
                ChatLog(
                    conversation_id=query.conversation_id,
                    user_id="user",
                    content=query.question,
                )
            )
            db_session.commit()
            
            # ì´ˆê¸° í”„ë¦¬í˜ì´ìŠ¤ ë©”ì‹œì§€ ì „ì†¡
            if prep_message:
                yield _sse("prep", prep_message)

            tool_results = []
            tool_results_texts = []
            executed_tool_names: List[str] = []

            # íˆ´ í˜¸ì¶œì´ ìˆìœ¼ë©´ ì‹¤í–‰
            if tool_calls:
                print("  [ìŠ¤íŠ¸ë¦¬ë°] íˆ´ í˜¸ì¶œ ì‹¤í–‰ ì¤‘...")
                for tc in tool_calls:
                    try:
                        tool_name = tc.function.name
                        args = json.loads(tc.function.arguments)
                        
                        # íˆ´ í˜¸ì¶œ
                        tool_result = call_tool(tool_name, args)
                        tool_results.append(tool_result)
                        executed_tool_names.append(tool_name)

                        result_text = f"[{tool_name}] ê²°ê³¼:\n{json.dumps(tool_result, ensure_ascii=False)}"
                        tool_results_texts.append(result_text)
                        
                        # ì†ŒìŠ¤ ì •ë³´ ì „ì†¡
                        # í´ë¼ì´ì–¸íŠ¸ì—ì„œ sourceë¥¼ ë°›ì•„ì„œ ë³„ë„ UIë¡œ í‘œì‹œ ê°€ëŠ¥
                        if tool_result:
                            yield _sse("sources", tool_result)
                            
                    except Exception as e:
                        error_msg = f"íˆ´ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"
                        print(error_msg)
                        traceback.print_exc()
                        yield _sse("error", error_msg)

            try:
                # íŒ”ë¡œì—… ë©”ì‹œì§€ êµ¬ì„±
                # ê³¼ê±° ëŒ€í™” ë¡œê·¸ë„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
                final_messages = history_messages + build_followup_messages(
                    query.question, prep_message, tool_results_texts, executed_tool_names or planned_tool_names
                )

                # ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
                stream = client.chat.completions.create(
                    model="gpt-4.1-mini", # ìµœì¢… ë‹µë³€ë„ gpt-4o ì‚¬ìš© ì¶”ì²œ
                    messages=final_messages,
                    stream=True,
                )

                collected_chunks = []
                for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        collected_chunks.append(content)
                        yield _sse("chunk", content)

                # ì „ì²´ ë‹µë³€ ì €ì¥
                full_answer = "".join(collected_chunks)
                
                # DBì— ì €ì¥ (assistant ë©”ì‹œì§€)
                db_session.add(
                    ChatLog(
                        conversation_id=query.conversation_id,
                        user_id="assistant",
                        content=full_answer,
                    )
                )
                db_session.commit()
                
                # ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
                yield _sse("done", {"status": "complete"})
                
            except Exception as e:
                error_msg = f"ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                print(error_msg)
                traceback.print_exc()
                yield _sse("error", error_msg)
        finally:
            db_session.close() # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚˜ë©´ DB ì„¸ì…˜ ë‹«ê¸°


    return StreamingResponse(_stream_response_generator(), media_type="text/event-stream")
