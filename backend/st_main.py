from fastapi import FastAPI, Depends
from pydantic import BaseModel
from openai import OpenAI
import os
import json
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse # ìŠ¤íŠ¸ë¦¬ë°ì‹ ë‹µë³€ì¶œë ¥

# âœ… DB ê´€ë ¨ import
from sqlalchemy.orm import Session
from DB.database import SessionLocal
from DB.models import ChatLog

# ë¼ìš°í„°
from routers import conversations, messages

# íˆ´ ëª¨ë“ˆ
from query_qdrant import ask as ask_law
from case_api import search_case_list, get_case_detail
from search_goolge import google_search

# íˆ´ ì •ì˜ ë¶ˆëŸ¬ì˜¤ê¸°
from tools_config import tools

app = FastAPI()
app.include_router(conversations.router)
app.include_router(messages.router)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===============================
# CORS
# ===============================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # React dev ì„œë²„ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===============================
# DB ì„¸ì…˜ ì˜ì¡´ì„±
# ===============================
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ===============================
# ìš”ì²­ Body
# ===============================
class Query(BaseModel):
    conversation_id: str
    question: str

# ===============================
# ì‹¤ì œ íˆ´ í•¨ìˆ˜ ë§¤í•‘
# ===============================
def call_tool(name: str, arguments: dict):
    print("âš¡ [TOOL CALL]")
    print(f"  ğŸ“Œ ì‹¤í–‰ëœ íˆ´: {name}")
    print(f"  ğŸ“ ì „ë‹¬ ì¸ì: {json.dumps(arguments, ensure_ascii=False)}")

    if name == "law":
        result = ask_law(arguments["query"])

    elif name == "search_cases":
        # ìƒì„¸ì¡°íšŒ ìš”ì²­ì¸ë° search_casesë¡œ ì˜ëª» ì˜¨ ê²½ìš° ë³´ì •
        if "case_id" in arguments:
            # case_id ê¸°ë°˜ ìƒì„¸ì¡°íšŒ
            result = get_case_detail(arguments["case_id"])
        elif "nb" in arguments and not arguments.get("query"):
            # ì‚¬ê±´ë²ˆí˜¸(nb)ë§Œ ë“¤ì–´ì˜¨ ê²½ìš° â†’ ìƒì„¸ì¡°íšŒë¡œ ë³´ì •
            result = get_case_detail(arguments["nb"])
        else:
            # ì •ìƒì ì¸ ê²€ìƒ‰ ìš”ì²­
            result = {"cases": search_case_list(**arguments)}

    elif name == "case_detail":
        result = get_case_detail(arguments["case_id"])

    elif name == "web_search":
        result = google_search(
            arguments["query"],
            arguments.get("count", 5),
            arguments.get("time_range", "any")
        )

    else:
        result = {"error": f"Unknown tool: {name}"}

    # âœ… íˆ´ ê²°ê³¼ë„ ë¡œê¹…
    preview = str(result)
    if len(preview) > 500:  # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
        preview = preview[:500] + " ... (ìƒëµ)"
    print(f"  âœ… íˆ´ ê²°ê³¼: {preview}\n")

    return result

    
# ===============================
# /ask_stream (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)
# ===============================
@app.post("/ask_stream")
def ask_stream(query: Query, db: Session = Depends(get_db)):

    # âœ… DBì—ì„œ ìµœê·¼ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    logs = (
        db.query(ChatLog)
        .filter(ChatLog.conversation_id == query.conversation_id)
        .order_by(ChatLog.created_at.desc())
        .limit(10)
        .all()
    )
    history_text = "\n".join([f"{log.role}: {log.content}" for log in reversed(logs)])

    # âœ… ëª¨ë¸ í˜¸ì¶œ (tool_calls í¬í•¨)
    first = client.chat.completions.create(
        model="gpt-5-mini",
        messages=[
            {
                "role": "system",
                "content": (
                    "ë„ˆëŠ” í•œêµ­ ì‹œì„¤ê´€ë¦¬ ë²•ë ¹Â·íŒë¡€Â·ë‰´ìŠ¤ ìƒë‹´ ì±—ë´‡ì´ë‹¤.\n"
                    "í•„ìš”í•˜ë©´ íˆ´ì„ í˜¸ì¶œí•˜ê³ , íˆ´ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•´ë¼.\n"
                    "- ë‹µë³€ ë¬¸ë‹¨ì€ ë‘ ì¤„ ê°„ê²©ìœ¼ë¡œ êµ¬ë¶„\n"
                    "- ë²•ë ¹ì€ [ë²•ë ¹ëª… ì œooì¡°](URL) í˜•ì‹ìœ¼ë¡œ ë§í¬\n"
                    "- ë‰´ìŠ¤ëŠ” [ê¸°ì‚¬ ì œëª©](URL) í˜•ì‹ìœ¼ë¡œ ë§í¬\n"
                    "- íŒë¡€ëŠ” ì‚¬ê±´ ë°°ê²½ â†’ íŒê²° ì´ìœ  â†’ ê²°ë¡  ìˆœìœ¼ë¡œ ìš”ì•½\n"
                ),
            },
            {"role": "user", "content": history_text},
            {"role": "user", "content": query.question},
        ],
        tools=tools,
        tool_choice="auto",
    )

    message = first.choices[0].message

    # âœ… íˆ´ì½œë§ì´ ì—†ì„ ë•Œ â†’ ë°”ë¡œ ìŠ¤íŠ¸ë¦¬ë°
    if not message.tool_calls:
        def generate_direct():
            with client.chat.completions.create(
                model="gpt-5-mini",
                stream=True,
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ ì‹œì„¤ê´€ë¦¬ ë²•ë ¹Â·íŒë¡€Â·ë‰´ìŠ¤ ìƒë‹´ ì±—ë´‡ì´ë‹¤."},
                    {"role": "user", "content": query.question},
                ],
            ) as response:
                for event in response:
                    delta = event.choices[0].delta
                    if "content" in delta and delta.content:
                        yield json.dumps({"type": "content", "delta": delta.content}) + "\n"

        return StreamingResponse(generate_direct(), media_type="application/jsonl")

    # âœ… íˆ´ ì‹¤í–‰ ê²°ê³¼ ëª¨ìœ¼ê¸°
    tool_results = []
    all_sources = []
    for tool_call in message.tool_calls:
        name = tool_call.function.name
        arguments = json.loads(tool_call.function.arguments)
        tool_result = call_tool(name, arguments)

        tool_results.append({
            "role": "tool",
            "tool_call_id": tool_call.id,
            "content": json.dumps(tool_result, ensure_ascii=False),
        })

        if "sources" in tool_result:
            all_sources.extend(tool_result["sources"])

    # âœ… íˆ´ ê²°ê³¼ ê¸°ë°˜ ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
    def generate_followup():
        with client.chat.completions.create(
            model="gpt-5-mini",
            stream=True,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë„ˆëŠ” í•œêµ­ ì‹œì„¤ê´€ë¦¬ ë²•ë ¹Â·íŒë¡€Â·ë‰´ìŠ¤ ìƒë‹´ ì±—ë´‡ì´ë‹¤.\n"
                        "ì•„ë˜ tool ê²°ê³¼ë¥¼ í™œìš©í•´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ ì‘ì„±í•˜ë¼.\n"
                        "- ë‹µë³€ ë¬¸ë‹¨ë§ˆë‹¤ ê´€ë ¨ ì¶œì²˜ ë²ˆí˜¸ ì¸ë±ìŠ¤([1], [2])ë¥¼ ë¶™ì—¬ë¼.\n"
                        "- ìµœì¢… ë‹µë³€ì€ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ë¼.\n"
                    ),
                },
                {"role": "user", "content": query.question},
                message,
                *tool_results,
            ],
        ) as response:
            for event in response:
                delta = event.choices[0].delta
                if "content" in delta and delta.content:
                    yield json.dumps({"type": "content", "delta": delta.content}) + "\n"

        yield json.dumps({"type": "sources", "data": all_sources}) + "\n"

    return StreamingResponse(generate_followup(), media_type="application/jsonl")