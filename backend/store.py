import os
import json
import hashlib
from dotenv import load_dotenv
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams
from openai import OpenAI

# ì´ íŒŒì¼ì€ JSON íŒŒì¼ì„ ì½ì–´ì„œ Qdrantì— ì„ë² ë”© ë²¡í„°ì™€ í•¨ê»˜ ì €ì¥í•©ë‹ˆë‹¤.

# --------------------------
# í™˜ê²½ì„¤ì •
# --------------------------
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Qdrant ì—°ê²°
qdrant = QdrantClient(host="localhost", port=6333)

COLLECTION_NAME = "laws"
DIM = 3072  # text-embedding-3-large ì°¨ì› ìˆ˜

# ì»¬ë ‰ì…˜ ì—†ìœ¼ë©´ ìƒì„±
if COLLECTION_NAME not in [c.name for c in qdrant.get_collections().collections]:
    qdrant.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=DIM, distance="Cosine")
    )

# --------------------------
# ìœ í‹¸ í•¨ìˆ˜
# --------------------------
def hash_id(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ í•´ì‹œí•´ì„œ Qdrant point_idë¡œ ì‚¬ìš©"""
    return hashlib.md5(text.encode("utf-8")).hexdigest()

def embed_text(text: str):
    """OpenAI ì„ë² ë”©"""
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-large"
    )
    return response.data[0].embedding

def build_article_text(article: dict) -> str:
    """ì¡°ë¬¸ JSON(dict) â†’ í•©ì³ì§„ í…ìŠ¤íŠ¸(str) ë³€í™˜"""
    lines = []
    lines.append(f"{article['law_name']} {article['article_number']}({article['article_title']})")

    if article.get("chapter"):
        lines.append(article["chapter"])
    if article.get("section"):
        lines.append(article["section"])
    if article.get("subsection"):
        lines.append(article["subsection"])

    for p in article.get("paragraphs", []):
        if p["paragraph_number"] == "ë³¸ë¬¸":
            lines.append(f"[ë³¸ë¬¸] {p['text']}")
        else:
            lines.append(f"[ì œ{p['paragraph_number']}í•­] {p['text']}")

        if "items" in p:
            for item in p["items"]:
                lines.append(f"  - [ì œ{item['item_number']}í˜¸] {item['text']}")
                if "subitems" in item:
                    for sub in item["subitems"]:
                        lines.append(f"    * [{sub['subitem_number']}ëª©] {sub['text']}")

    return "\n".join(lines).strip()

# --------------------------
# JSON â†’ ì„ë² ë”© â†’ Qdrant ì €ì¥
# --------------------------
def process_json(json_file):
    with open(json_file, "r", encoding="utf-8") as f:
        chunks = json.load(f)

    points = []
    for c in chunks:
        full_text = build_article_text(c)
        vector = embed_text(full_text)
        point_id = hash_id(c["article_number"] + c["article_title"])

        payload = {
            "law_name": c.get("law_name"),
            "article_number": c["article_number"],
            "article_title": c["article_title"],
            "chapter": c.get("chapter"),
            "section": c.get("section"),
            "subsection": c.get("subsection"),
            "text": full_text
        }

        points.append(PointStruct(id=point_id, vector=vector, payload=payload))

    qdrant.upsert(collection_name=COLLECTION_NAME, points=points)
    print(f"âœ… {json_file} â†’ {len(points)}ê°œ ì—…ë¡œë“œ ì™„ë£Œ")

# --------------------------
# ì‹¤í–‰
# --------------------------
if __name__ == "__main__":
    json_dir = "texts"
    for file in os.listdir(json_dir):
        if file.endswith(".json") and not file.endswith("_metadata.json"):
            process_json(os.path.join(json_dir, file))
    print("ğŸ‰ ëª¨ë“  JSON ì—…ë¡œë“œ ì™„ë£Œ")
